"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –≤—ã–≥—Ä—É–∑–∫–∏.

–í—ã–ø–æ–ª–Ω—è–µ—Ç:
1. –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –∫–æ–ª–æ–Ω–∫–µ "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"
2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ –∑–∞–º–µ—Ç–æ–∫ –¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
3. –û—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–º–µ—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
4. –ó–∞–Ω—É–ª–µ–Ω–∏–µ "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ" –¥–ª—è —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º "–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ"
5. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
"""

from pathlib import Path
from typing import Dict, List, Tuple, Any
import pandas as pd
from openpyxl import load_workbook
from loguru import logger


def post_process_excel_file(file_path: Path) -> None:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É Excel —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ –≤—ã–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.

    Args:
        file_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    logger.info(f"üîß –ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {file_path}")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞–±–æ—á—É—é –∫–Ω–∏–≥—É
        workbook = load_workbook(file_path)
        report_sheet = workbook["–û—Ç—á–µ—Ç"]

        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏
        column_mapping = _find_columns(report_sheet)
        logger.info(f"üìã –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: {column_mapping}")

        # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ DataFrame –¥–ª—è —É–¥–æ–±–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        df = _read_sheet_to_dataframe(report_sheet, column_mapping)
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É
        df_processed = _process_duplicates(df, column_mapping)
        df_processed = _process_negative_excess(df_processed, column_mapping)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ Excel
        _save_dataframe_to_sheet(df_processed, report_sheet, column_mapping)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        workbook.save(file_path)
        logger.info(f"‚úÖ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {file_path}")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        logger.exception("–ü–æ–ª–Ω—ã–π traceback:")
        raise


def _find_columns(sheet) -> Dict[str, int]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ –ª–∏—Å—Ç–µ.

    Args:
        sheet: –õ–∏—Å—Ç Excel —Ñ–∞–π–ª–∞

    Returns:
        Dict —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–ª–æ–Ω–æ–∫ –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å–∞–º–∏
    """
    column_mapping = {}

    # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
    for col in range(1, sheet.max_column + 1):
        header = sheet.cell(row=1, column=col).value
        if header:
            header_str = str(header).strip().lower()

            if "–ø–æ—Ç–µ—Ä—è–Ω–Ω" in header_str:
                column_mapping["–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"] = col
            elif "—Ä–µ–≥–∏–æ–Ω" in header_str:
                column_mapping["–†–µ–≥–∏–æ–Ω"] = col
            elif "–∑–∞–º–µ—Ç–∫" in header_str:
                column_mapping["–ó–∞–º–µ—Ç–∫–∏"] = col
            elif "–ø—Ä–µ–≤—ã—à–µ–Ω" in header_str:
                column_mapping["–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ"] = col
            elif "–Ω–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π" in header_str:
                column_mapping["–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π"] = col

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞–π–¥–µ–Ω—ã
    required_columns = ["–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ", "–†–µ–≥–∏–æ–Ω", "–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ"]
    missing_columns = [col for col in required_columns if col not in column_mapping]

    if missing_columns:
        raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")

    # –ó–∞–º–µ—Ç–∫–∏ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    if "–ó–∞–º–µ—Ç–∫–∏" not in column_mapping:
        logger.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ '–ó–∞–º–µ—Ç–∫–∏' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞")
        column_mapping["–ó–∞–º–µ—Ç–∫–∏"] = None

    return column_mapping


def _read_sheet_to_dataframe(sheet, column_mapping: Dict[str, int]) -> pd.DataFrame:
    """
    –ß–∏—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–∏—Å—Ç–∞ –≤ DataFrame.

    Args:
        sheet: –õ–∏—Å—Ç Excel —Ñ–∞–π–ª–∞
        column_mapping: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å–∞–º–∏

    Returns:
        DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
    """
    data = []

    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞—á–∏–Ω–∞—è —Å–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–∏ (–ø–µ—Ä–≤–∞—è - –∑–∞–≥–æ–ª–æ–≤–∫–∏)
    for row in range(2, sheet.max_row + 1):
        row_data = {}

        for col_name, col_idx in column_mapping.items():
            if col_idx is not None:
                cell_value = sheet.cell(row=row, column=col_idx).value
                row_data[col_name] = cell_value
            else:
                row_data[col_name] = ""  # –î–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
        row_data["_row_index"] = row
        data.append(row_data)

    return pd.DataFrame(data)


def _process_duplicates(df: pd.DataFrame, column_mapping: Dict[str, int]) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –∫–æ–ª–æ–Ω–∫–µ "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ".

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        column_mapping: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å–∞–º–∏

    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
    """
    logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –∫–æ–ª–æ–Ω–∫–µ '–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ'")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"
    lost_groups = df.groupby("–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ")

    total_duplicates = 0
    processed_groups = 0

    for lost_value, group in lost_groups:
        if pd.isna(lost_value) or lost_value == 0:
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

        if len(group) == 1:
            continue  # –ù–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–∞ –≥—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è '{lost_value}': {len(group)} —Å—Ç—Ä–æ–∫")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        region_groups = group.groupby("–†–µ–≥–∏–æ–Ω")

        for region, region_group in region_groups:
            if len(region_group) == 1:
                continue  # –ù–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Ä–µ–≥–∏–æ–Ω–µ

            logger.info(f"   üìç –†–µ–≥–∏–æ–Ω '{region}': {len(region_group)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
            best_row_idx = _find_best_row_by_notes(region_group)

            # –ó–∞–Ω—É–ª—è–µ–º "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ" –¥–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ
            for idx, row in region_group.iterrows():
                if idx != best_row_idx:
                    df.loc[idx, "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"] = 0
                    total_duplicates += 1
                    logger.info(f"      üóëÔ∏è –ó–∞–Ω—É–ª–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {row['_row_index']} (–º–∞—Å—Å–æ–≤–∞—è: {row.get('–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π', 'N/A')})")
                else:
                    logger.info(f"      ‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {row['_row_index']} (–º–∞—Å—Å–æ–≤–∞—è: {row.get('–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π', 'N/A')}) - –Ω–∞–∏–±–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–µ—Ç–æ–∫")

            processed_groups += 1

    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {processed_groups} –≥—Ä—É–ø–ø, {total_duplicates} —Å—Ç—Ä–æ–∫ –∑–∞–Ω—É–ª–µ–Ω–æ")
    return df


def _find_best_row_by_notes(group: pd.DataFrame) -> int:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–º–µ—Ç–æ–∫ –≤ –≥—Ä—É–ø–ø–µ.
    
    –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞:
    1. –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ "–ó–∞–º–µ—Ç–∫–∏" - –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–º–µ—Ç–æ–∫
    2. –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ "–ó–∞–º–µ—Ç–∫–∏" –Ω–µ—Ç - –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º "–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π"
    3. –ï—Å–ª–∏ –∏ "–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π" –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
    
    Args:
        group: –ì—Ä—É–ø–ø–∞ —Å—Ç—Ä–æ–∫ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ä–µ–≥–∏–æ–Ω–æ–º –∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"
        
    Returns:
        –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–º–µ—Ç–æ–∫
    """
    if "–ó–∞–º–µ—Ç–∫–∏" not in group.columns:
        # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ "–ó–∞–º–µ—Ç–∫–∏" –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º "–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π" –∫–∞–∫ –∫—Ä–∏—Ç–µ—Ä–∏–π
        logger.info("   üìù –ö–æ–ª–æ–Ω–∫–∞ '–ó–∞–º–µ—Ç–∫–∏' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º '–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π' –¥–ª—è –≤—ã–±–æ—Ä–∞")
        return _find_best_row_by_mass_number(group)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–µ—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
    notes_counts = []
    for idx, row in group.iterrows():
        notes = row["–ó–∞–º–µ—Ç–∫–∏"]
        if pd.isna(notes) or notes == "":
            count = 0
        else:
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç –∑–∞–º–µ—Ç–æ–∫:
            # 1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ (—Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö \n)
            # 2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ (—Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–∞–º–∏)
            # 3. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤
            notes_str = str(notes).strip()
            line_count = len(notes_str.split('\n')) if '\n' in notes_str else 1
            word_count = len(notes_str.split()) if notes_str else 0
            char_count = len(notes_str)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–æ–∫, –∑–∞—Ç–µ–º —Å–ª–æ–≤, –∑–∞—Ç–µ–º —Å–∏–º–≤–æ–ª–æ–≤
            count = line_count * 1000 + word_count * 10 + char_count
            
            logger.info(f"      üìù –°—Ç—Ä–æ–∫–∞ {row['_row_index']}: {line_count} —Å—Ç—Ä–æ–∫, {word_count} —Å–ª–æ–≤, {char_count} —Å–∏–º–≤–æ–ª–æ–≤ (–æ—Ü–µ–Ω–∫–∞: {count})")
        
        notes_counts.append((count, idx))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–º–µ—Ç–æ–∫
    notes_counts.sort(key=lambda x: x[0], reverse=True)
    
    best_idx = notes_counts[0][1]
    best_row = group.loc[best_idx]
    logger.info(f"   ‚úÖ –í—ã–±—Ä–∞–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {best_row['_row_index']} —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–º–µ—Ç–æ–∫")
    
    return best_idx


def _find_best_row_by_mass_number(group: pd.DataFrame) -> int:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –Ω–æ–º–µ—Ä–æ–º –º–∞—Å—Å–æ–≤–æ–π –≤ –≥—Ä—É–ø–ø–µ.
    
    Args:
        group: –ì—Ä—É–ø–ø–∞ —Å—Ç—Ä–æ–∫ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ä–µ–≥–∏–æ–Ω–æ–º –∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"
        
    Returns:
        –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –Ω–æ–º–µ—Ä–æ–º –º–∞—Å—Å–æ–≤–æ–π
    """
    if "–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π" not in group.columns:
        # –ï—Å–ª–∏ –∏ –∫–æ–ª–æ–Ω–∫–∏ "–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π" –Ω–µ—Ç, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
        logger.info("   üìù –ö–æ–ª–æ–Ω–∫–∞ '–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É")
        return group.index[0]
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –Ω–æ–º–µ—Ä–æ–º –º–∞—Å—Å–æ–≤–æ–π
    max_mass_number = None
    best_idx = group.index[0]
    
    for idx, row in group.iterrows():
        mass_number = row["–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π"]
        if pd.isna(mass_number):
            continue
            
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤—É—é —á–∞—Å—Ç—å –∏–∑ –Ω–æ–º–µ—Ä–∞ –º–∞—Å—Å–æ–≤–æ–π
        try:
            # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–∞, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏—Ö
            import re
            numbers = re.findall(r'\d+', str(mass_number))
            if numbers:
                numeric_value = int(''.join(numbers))
                if max_mass_number is None or numeric_value > max_mass_number:
                    max_mass_number = numeric_value
                    best_idx = idx
                    logger.info(f"      üìù –°—Ç—Ä–æ–∫–∞ {row['_row_index']}: –Ω–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π '{mass_number}' -> {numeric_value}")
        except (ValueError, TypeError):
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
            if max_mass_number is None or str(mass_number) > str(max_mass_number):
                max_mass_number = mass_number
                best_idx = idx
                logger.info(f"      üìù –°—Ç—Ä–æ–∫–∞ {row['_row_index']}: –Ω–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π '{mass_number}' (—Å—Ç—Ä–æ–∫–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)")
    
    logger.info(f"   ‚úÖ –í—ã–±—Ä–∞–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {group.loc[best_idx]['_row_index']} —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –Ω–æ–º–µ—Ä–æ–º –º–∞—Å—Å–æ–≤–æ–π")
    return best_idx


def _process_negative_excess(df: pd.DataFrame, column_mapping: Dict[str, int]) -> pd.DataFrame:
    """
    –ó–∞–Ω—É–ª—è–µ—Ç "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ" –¥–ª—è —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º "–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ".

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        column_mapping: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å–∞–º–∏

    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
    """
    logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º '–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ'")

    # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫–∏ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ–º
    negative_excess_mask = pd.to_numeric(df["–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ"], errors='coerce') < 0

    negative_count = negative_excess_mask.sum()

    if negative_count == 0:
        logger.info("‚úÖ –°—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º '–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return df

    logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {negative_count} —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º '–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ'")

    # –ó–∞–Ω—É–ª—è–µ–º "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ" –¥–ª—è —ç—Ç–∏—Ö —Å—Ç—Ä–æ–∫
    df.loc[negative_excess_mask, "–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ"] = 0

    # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏
    negative_rows = df[negative_excess_mask]
    for idx, row in negative_rows.iterrows():
        logger.info(f"   üóëÔ∏è –ó–∞–Ω—É–ª–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {row['_row_index']} (–º–∞—Å—Å–æ–≤–∞—è: {row.get('–ù–æ–º–µ—Ä –º–∞—Å—Å–æ–≤–æ–π', 'N/A')}, –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ: {row['–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ']})")

    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {negative_count} —Å—Ç—Ä–æ–∫ –∑–∞–Ω—É–ª–µ–Ω–æ")
    return df


def _save_dataframe_to_sheet(df: pd.DataFrame, sheet, column_mapping: Dict[str, int]) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤ –ª–∏—Å—Ç Excel.

    Args:
        df: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
        sheet: –õ–∏—Å—Ç Excel —Ñ–∞–π–ª–∞
        column_mapping: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å–∞–º–∏
    """
    logger.info("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ Excel —Ñ–∞–π–ª")

    for idx, row in df.iterrows():
        row_index = row["_row_index"]

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for col_name, col_idx in column_mapping.items():
            if col_idx is not None and col_name in df.columns:
                sheet.cell(row=row_index, column=col_idx, value=row[col_name])

    logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Excel —Ñ–∞–π–ª")
